{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tecnologias e Aplicações - Computação Gráfica\n",
    "\n",
    "\n",
    "Grupo:\n",
    "\n",
    "* A82202 - Joel Gama \n",
    "* A82491 - Tiago Pinheiro\n",
    "* A75362 - Vitor Gomes\n",
    "\n",
    "Dataset utilizado: []()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "https://www.youtube.com/watch?v=yH1cF7GnoIo    \n",
    "\n",
    "https://www.datacamp.com/community/tutorials/tensorflow-tutorial    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size\n",
    "\n",
    "Batch size is an important parameter when training a network. It can influence speed and generalization, not necessarily in the same direction. There is no golden rule for the batch size but 32 is a commom number to start with.\n",
    "\n",
    "See: https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/\n",
    "\n",
    "Try with different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('gtsrb/train_images/')\n",
    "signs = list(data_dir.glob('00001/*'))\n",
    "  \n",
    "classNames = np.array(os.listdir(data_dir))\n",
    "classNames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  return parts[-2] == classNames\n",
    "\n",
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [32,32])\n",
    "\n",
    "def get_bytes_and_label(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label\n",
    "\n",
    "def validacao(file_path,valsplit):\n",
    "    \n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    seq_num = tf.strings.to_number(tf.strings.split(parts[-1], '_')[0])\n",
    "    \n",
    "    return (int(seq_num)%round(1/valsplit)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images takes place in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "listset = tf.data.Dataset.list_files(\"gtsrb/train_images/*/*.png\")\n",
    "\n",
    "valsplit = 0.2\n",
    "\n",
    "valset = listset.filter(lambda f: validacao(f,valsplit))\n",
    "valset = valset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "trainset = listset.filter(lambda f: not(validacao(f,valsplit)))\n",
    "trainset = trainset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about image shape and size of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for image, label in dataset.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  \n",
    "dataset_length = [i for i,_ in enumerate(dataset)][-1] + 1\n",
    "\n",
    "print(\"Total images in dataset: \",dataset_length)\n",
    "'''\n",
    "for image, label in valset.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  \n",
    "valset_length = [i for i,_ in enumerate(valset)][-1] + 1\n",
    "print(\"Total images in dataset: \",valset_length)\n",
    "\n",
    "for image, label in trainset.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  \n",
    "trainset_length = [i for i,_ in enumerate(trainset)][-1] + 1\n",
    "print(\"Total images in dataset: \",trainset_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(buffer_size = dataset_length)\n",
    "    dataset = dataset.batch(batch_size=BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.repeat()\n",
    "    '''\n",
    "    valset = valset.cache()\n",
    "    valset = valset.shuffle(buffer_size = valset_length)\n",
    "    valset = valset.batch(batch_size=BATCH_SIZE)\n",
    "    valset = valset.prefetch(buffer_size=AUTOTUNE)\n",
    "    valset = valset.repeat()\n",
    "\n",
    "    trainset = trainset.cache()\n",
    "    trainset = trainset.shuffle(buffer_size = trainset_length)\n",
    "    trainset = trainset.batch(batch_size=BATCH_SIZE)\n",
    "    trainset = trainset.prefetch(buffer_size=AUTOTUNE)\n",
    "    trainset = trainset.repeat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSplit = 0.8\n",
    "\n",
    "testset = tf.data.Dataset.list_files(\"gtsrb/test_images/*/*.png\")\n",
    "print(testset)\n",
    "testset = testset.map(get_bytes_and_label, num_parallel_calls = AUTOTUNE)\n",
    "testset = testset.batch(batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show a batch of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "  columns = 6\n",
    "  rows = BATCH_SIZE / columns + 1  \n",
    "  plt.figure(figsize=(10, 2 * rows))\n",
    "  for n in range(BATCH_SIZE):\n",
    "      ax = plt.subplot(rows, columns, n+1)\n",
    "      plt.imshow((image_batch[n]))\n",
    "      plt.title(classNames[label_batch[n]==1][0])\n",
    "      plt.axis('off')\n",
    "        \n",
    "        \n",
    "image_batch, label_batch = next(iter(trainset))        \n",
    "show_batch(image_batch, label_batch.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def cnn55D3L2FC(classCount, imgSize, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (5, 5), padding='same',\n",
    "                     input_shape=(imgSize, imgSize, channels),\n",
    "                     activation='relu'))                     \n",
    "    model.add(Conv2D(64, (5, 5), activation='relu') ) \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu') )   \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(classCount, activation='softmax')) #Não mudar, este dá valores entre 0 e 1\n",
    "\n",
    "    \n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=[ metrics.categorical_accuracy])\n",
    "    return model\n",
    "\n",
    "model = cnn55D3L2FC(43, 32, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw a diagram of the network\n",
    "\n",
    "This requires installing some packages, namely graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a table with model information\n",
    "\n",
    "When building a model kee an eye on the number of trainable parameters. Try to keep it below 10 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a random split to create a validation set\n",
    "\n",
    "Note that due to the way the GTSRB is build (using video sequences) this is not an ideal approach. Try to partition the set manually, selecting a few sequences for validation purposes. Load the training and validation sets independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "train_size = int(0.8 * dataset_length)\n",
    "val_size = int(0.2 * dataset_length)\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(val_size)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(trainset, steps_per_epoch = trainset_length/BATCH_SIZE,\n",
    "          epochs=20, validation_data = valset, validation_steps= valset_length/BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the test set\n",
    "\n",
    "This is the accuracy number that really matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class_names = np.array(['limite 20','limite 30', 'limite 50', 'limmite 60', 'limite 70', 'limite 80', 'fim limite 80', 'limite 100', 'limite 120', 'proibição de ultrapassar', 'proibição de ultrapassar para pesados', 'cruzamento', 'via com prioridade', 'cedência de passagem', 'stop', 'trânsito proibido', 'trânsito proibido mercadorias', 'sentido proibido', 'perigo qualquer', 'curva esquerda', 'curva direita', 'curva esquerda e contracurva', 'lomba ou depressão', 'pavimento escorregadio', 'passagem estreita', 'trabalhos na via', 'sinalização luminosa', 'travessia de peões', 'crianças', 'ciclistas', 'neve', 'animais', 'fim proibição', 'obrigação direita', 'obrigação esquerda', 'obrigação frente', 'obrigação direita ou frente', 'obrigação frente ou esquerda', 'contornar pela direita', 'contornar pela esquerda', 'obrigação rotunda', 'fim proibição ultrapassagem', 'fim proibição ultrapassagem pesados'])\n",
    "\n",
    "def plot_image(predictions_array, true_label, img):\n",
    "  #predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "    \n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  \n",
    "    \n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  true_label = np.argmax(true_label)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "  #predictions_array, true_label = predictions_array, true_label[i]\n",
    "  true_label = np.argmax(true_label)\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(43))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(43), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n",
    "\n",
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 30\n",
    "num_cols = 1\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(8*2*2*num_cols, 2*num_rows))\n",
    "j=0\n",
    "for i in testset.take(1):\n",
    "  a = model.predict(i)\n",
    "  image,label = i\n",
    "  for j in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*j+1)\n",
    "    plot_image(a[j], label.numpy()[j], image.numpy()[j])\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*j+2)\n",
    "    plot_value_array(a[j], label.numpy()[j])\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class_names = np.array(['limite 20','limite 30', 'limite 50', 'limmite 60', 'limite 70', 'limite 80', 'fim limite 80', 'limite 100', 'limite 120', 'proibição de ultrapassar', 'proibição de ultrapassar para pesados', 'cruzamento', 'via com prioridade', 'cedência de passagem', 'stop', 'trânsito proibido', 'trânsito proibido mercadorias', 'sentido proibido', 'perigo qualquer', 'curva esquerda', 'curva direita', 'curva esquerda e contracurva', 'lomba ou depressão', 'pavimento escorregadio', 'passagem estreita', 'trabalhos na via', 'sinalização luminosa', 'travessia de peões', 'crianças', 'ciclistas', 'neve', 'animais', 'fim proibição', 'obrigação direita', 'obrigação esquerda', 'obrigação frente', 'obrigação direita ou frente', 'obrigação frente ou esquerda', 'contornar pela direita', 'contornar pela esquerda', 'obrigação rotunda', 'fim proibição ultrapassagem', 'fim proibição ultrapassagem pesados'])\n",
    "\n",
    "def plot_image(predictions_array, true_label, img):\n",
    "  #predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "    \n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  \n",
    "    \n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  true_label = np.argmax(true_label)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "\n",
    "def plot_value_array(predictions_array, true_label):\n",
    "  #predictions_array, true_label = predictions_array, true_label[i]\n",
    "  true_label = np.argmax(true_label)\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(43))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(43), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n",
    "\n",
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 30\n",
    "num_cols = 1\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(8*2*2*num_cols, 2*num_rows))\n",
    "errados=0\n",
    "for i in testset.take(-1):\n",
    "  a = model.predict(i)\n",
    "  image,label = i\n",
    "  for j in range(BATCH_SIZE):\n",
    "    if np.argmax(a[j]) != np.argmax(label.numpy()[j]):\n",
    "      plt.subplot(num_rows, 2*num_cols, 2*errados+1)\n",
    "      plot_image(a[j], label.numpy()[j], image.numpy()[j])\n",
    "      plt.subplot(num_rows, 2*num_cols, 2*errados+2)\n",
    "      plot_value_array(a[j], label.numpy()[j])\n",
    "      errados = errados + 1\n",
    "    if errados >= num_images:\n",
    "        break\n",
    "  if errados >= num_images:\n",
    "    break\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
